# Distributed Task Queue partitioning and Rebalancing

## üá∫üá∏ EN


## üáßüá∑ PT-BR

## O que √©

√â uma fila de tarefas distribu√≠das, que automaticamente se particiona e faz rebalanceamento.

Aqui, vamos ter m√∫ltiplas filas no Redis, e vamos ter workers em processos diferentes, se coordenando simultaneamente. Um worker vai pegar uma tarefa da fila, vai processar e depois pegar a pr√≥xima.

### <span style="color:rgb(0, 255, 136)">Cen√°rio</span>

Imagina que temos um sistema que precisa processar **milhares de tarefas por segundo.** Como:

- Processar imagens
- Enviar e-mails
- Gerar relat√≥rios

Qualquer tarefa que pode demorar algum tempo. Se fizermos isso em apenas um servidores, ele n√£o daria conta, ia entrar em sobrecarga, dependendo do n√≠vel de escala. Ent√£o, precisamos distribuir esse trabalho entre v√°rios servidores.

### <span style="color:rgb(0, 255, 136)">Problemas</span>

Mas existem **problemas**:

- Como coordenar isso?
- Como garantimos que cada tarefa seja processada exatamente uma vez?
- Como dividimos o trabalho de forma justa entre os servidores?
- O que acontece quando um servidor morre ou quando adicionamos servidores novos?

### Abordagens poss√≠veis

Podemos resolver esses problemas das seguintes formas:

1. Ter um Coordenador central, uma entidade centralizada que coordena todos os trabalhos. Por√©m tem um problema nessa abordagem, essa entidade central √© um ponto √∫nico de falha e um gargalo ao sistema. Se ele falhar o sistema todo falha e perdemos em **disponibilidade.** (availability - CAP)
2. A segunda abordagem √© ter um sistema onde os pr√≥prios workers se coordenam entre si, sem entidade central, se rebalanceando de forma din√¢mica e inteligente. Essa √© a abordagem desse projeto.

### Ideias Centrais desse projeto

Aqui temos 3 ideias centrais:

1. Usar **particionamento:** dividir todas as tarefas poss√≠veis em 256 grupos fixos, chamados **partitions**.
2. Usar **consistent hashing:** para decidir qual worker √© respons√°vel por quais partitions de forma determin√≠stica. Ou seja, um roteamento preciso para o sistema.
3. Usar **etcd**: para os workers se descobrirem e coordenarem quem est√° vivo no cluster.

Dessa forma, os **workers** podem olhar ao etcd e ver quem est√° vivo, roda o mesmo algoritmo de consistent hashing e todos chegam na mesma conclus√£o sobre quem deve processar quais partitions. √â um **consenso - consensus protocol**.